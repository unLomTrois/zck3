/// This module parses the tokens generated by the lexer into an abstract syntax tree (AST).
const std = @import("std");
const lexer_mod = @import("lexer.zig");
const Lexer = lexer_mod.Lexer;
const Token = lexer_mod.Token;

const Block = struct {
    list: std.ArrayList(BlockItem),

    pub fn init(allocator: std.mem.Allocator) Block {
        return Block{ .list = std.ArrayList(BlockItem).init(allocator) };
    }

    pub fn deinit(self: *Block) void {
        self.list.deinit();
    }
};

const BlockItem = union(enum) {
    value: Token,
    field: Field,

    pub inline fn init_token(token: Token) BlockItem {
        return BlockItem{ .value = token };
    }

    pub inline fn init_field(field: Field) BlockItem {
        return BlockItem{ .field = field };
    }
};

const Field = struct {
    key: Token,
    comparator: Token,
    value: BV,

    pub inline fn init(key: Token, comparator: Token, value: BV) Field {
        return Field{ .key = key, .comparator = comparator, .value = value };
    }
};

const BV = union(enum) {
    block: Block,
    value: Token,

    pub inline fn init_block(block: Block) BV {
        return BV{ .block = block };
    }

    pub inline fn init_value(value: Token) BV {
        return BV{ .value = value };
    }
};

const Parser = struct {
    allocator: std.mem.Allocator,
    lexer: *Lexer,

    pub fn init(allocator: std.mem.Allocator, lexer: *Lexer) Parser {
        return Parser{ .allocator = allocator, .lexer = lexer };
    }

    // Temporary LL(1) parser, will be replaced with LR(1) parser later
    pub fn parse(self: *Parser) error{ OutOfMemory, UnexpectedEOF, UnexpectedToken }!Block {
        return try self.parse_block();
    }

    fn parse_block(self: *Parser) error{ OutOfMemory, UnexpectedEOF, UnexpectedToken }!Block {
        var block = Block.init(self.allocator);

        while (self.lexer.next()) |token| {
            switch (token.tag) {
                .literal_number => {
                    try block.list.append(BlockItem.init_token(token));
                },
                .identifier => {
                    const field = try self.parse_field(token);
                    try block.list.append(BlockItem.init_field(field));
                },
                .r_brace => {
                    return block;
                },
                else => {
                    std.debug.print("expected {s}, got {s}\n", .{ @tagName(.identifier), @tagName(token.tag) });
                    return error.UnexpectedToken;
                },
            }
        }

        return block;
    }

    fn parse_field(self: *Parser, key: Token) error{ OutOfMemory, UnexpectedEOF, UnexpectedToken }!Field {
        const comparator = try self.eat(.equal);
        const value = try self.parse_bv();
        return Field.init(key, comparator, value);
    }

    fn parse_bv(self: *Parser) error{ OutOfMemory, UnexpectedEOF, UnexpectedToken }!BV {
        // can be a block or a value
        const token = self.lexer.next() orelse return error.UnexpectedEOF;
        switch (token.tag) {
            .l_brace => {
                const block = try self.parse_block();
                return BV.init_block(block);
            },
            .identifier => {
                return BV.init_value(token);
            },
            else => {
                std.debug.print("expected {s}, got {s}\n", .{ @tagName(.identifier), @tagName(token.tag) });
                return error.UnexpectedToken;
            },
        }
    }

    fn eat(self: *Parser, tag: Token.Tag) error{ UnexpectedEOF, UnexpectedToken }!Token {
        const token = self.lexer.next() orelse return error.UnexpectedEOF;
        if (token.tag != tag) {
            std.debug.print("expected {s}, got {s}\n", .{ @tagName(tag), @tagName(token.tag) });
            return error.UnexpectedToken;
        }

        return token;
    }
};

test "empty block" {
    const source = "";

    var lexer = Lexer.init(source);
    var parser = Parser.init(std.testing.allocator, &lexer);

    var ast = try parser.parse();
    defer ast.deinit();

    try std.testing.expectEqualDeep(ast, Block.init(std.testing.allocator));
}

test "block with one token (non standard grammar)" {
    const source = "1";

    var lexer = Lexer.init(source);
    var parser = Parser.init(std.testing.allocator, &lexer);

    var ast = try parser.parse();
    defer ast.deinit();

    std.debug.print("ast: {any}\n", .{ast.list.items});

    var expected = Block.init(std.testing.allocator);
    defer expected.deinit();
    try expected.list.append(BlockItem.init_token(
        Token{ .tag = .literal_number, .start = 0, .end = 1 },
    ));

    try std.testing.expectEqualDeep(expected, ast);
}

test "key = value" {
    const source = "key = value";

    var lexer = Lexer.init(source);
    var parser = Parser.init(std.testing.allocator, &lexer);

    var ast = try parser.parse();
    defer ast.deinit();

    var expected = Block.init(std.testing.allocator);
    defer expected.deinit();
    try expected.list.append(BlockItem.init_field(Field.init(
        Token{ .tag = .identifier, .start = 0, .end = 3 },
        Token{ .tag = .equal, .start = 4, .end = 5 },
        BV.init_value(Token{ .tag = .identifier, .start = 6, .end = 11 }),
    )));

    try std.testing.expectEqualDeep(expected, ast);
}

test "key = { }" {
    const source = "key = { }";

    var lexer = Lexer.init(source);
    var parser = Parser.init(std.testing.allocator, &lexer);

    var ast = try parser.parse();
    defer ast.deinit();

    var expected = Block.init(std.testing.allocator);
    defer expected.deinit();
    try expected.list.append(BlockItem.init_field(Field.init(
        Token{ .tag = .identifier, .start = 0, .end = 3 },
        Token{ .tag = .equal, .start = 4, .end = 5 },
        BV.init_block(Block.init(std.testing.allocator)),
    )));

    try std.testing.expectEqualDeep(expected, ast);
}
